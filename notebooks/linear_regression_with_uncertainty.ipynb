{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": { "editable": false, "deletable": false },
   "source": [
    "# Ethical Reminder (from the Lab Alliance Compact)\n",
    "\n",
    "- Data belongs to truth, not expectations; document steps transparently.\n",
    "- Perform **your own analysis**; credit all sources and collaborators properly.\n",
    "- Communicate respectfully; ask for help early; uphold psychological safety.\n",
    "\n",
    "> By proceeding, you acknowledge the Compact and agree to act accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Pilot: Weighted Least Squares with Uncertainties\n",
    "\n",
    "**Learning goals**\n",
    "1. Generate synthetic data with known ground truth.\n",
    "2. Perform **weighted** linear regression using `scipy.optimize.curve_fit`.\n",
    "3. Interpret fit parameters, standard errors, confidence intervals.\n",
    "4. Diagnose fits via **residuals** and χ² per degree of freedom.\n",
    "5. Understand the distinction between **statistical** and **systematic** uncertainties.\n",
    "\n",
    "**Model:**  \\( y = a x + b \\)\n",
    "\n",
    "This pilot complements *Part 4 · Statistics & Data Analysis* in the handbook.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def model(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "# --- Ground truth and synthetic data ---\n",
    "a_true, b_true = 2.0, -1.0\n",
    "N = 30\n",
    "x = np.linspace(0, 10, N)\n",
    "\n",
    "# Heteroscedastic noise: sigma grows mildly with x\n",
    "sigma = 0.2 + 0.02*x\n",
    "y = model(x, a_true, b_true) + rng.normal(0.0, sigma)\n",
    "\n",
    "x[:5], y[:5], sigma[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data with error bars\n",
    "Always label axes with units (if applicable) and show uncertainties on measured points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(x, y, yerr=sigma, fmt='o', capsize=3)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Synthetic data with heteroscedastic noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted fit with `curve_fit`\n",
    "`curve_fit` supports weights via `sigma` and `absolute_sigma=True`.\n",
    "\n",
    "- `sigma` = standard deviation (uncertainty) of each point.\n",
    "- `absolute_sigma=True` tells `curve_fit` to treat these as **absolute** uncertainties.\n",
    "- The returned covariance then reflects the scale of `sigma`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "p0 = [1.0, 0.0]  # initial guess [a, b]\n",
    "popt, pcov = curve_fit(model, x, y, p0=p0, sigma=sigma, absolute_sigma=True)\n",
    "a_fit, b_fit = popt\n",
    "a_err, b_err = np.sqrt(np.diag(pcov))\n",
    "print(f\"Fit: a = {a_fit:.4f} ± {a_err:.4f}, b = {b_fit:.4f} ± {b_err:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness-of-fit and residuals\n",
    "The **reduced** chi-squared (χ²_ν) is informative:\n",
    "χ² = Σ [(y_i - f(x_i))² / σ_i²],  χ²_ν = χ²/(N - p). Values near 1 suggest consistent uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_fit = model(x, *popt)\n",
    "res = y - y_fit\n",
    "chi2 = np.sum((res/sigma)**2)\n",
    "ndof = len(x) - len(popt)\n",
    "chi2_red = chi2/ndof\n",
    "print(f\"chi2 = {chi2:.2f}, ndof = {ndof}, chi2_red = {chi2_red:.2f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6,6), sharex=True)\n",
    "ax1.errorbar(x, y, yerr=sigma, fmt='o', capsize=3, label='data')\n",
    "ax1.plot(x, y_fit, label='fit')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.legend()\n",
    "ax1.set_title('Fit and data')\n",
    "\n",
    "ax2.axhline(0, lw=1)\n",
    "ax2.errorbar(x, res, yerr=sigma, fmt='o', capsize=3)\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('residuals')\n",
    "ax2.set_title('Residuals (with y-errors)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "From the covariance matrix `pcov`, 1σ standard errors are sqrt of the diagonal.\n",
    "Approximate 95% CIs: a ± 1.96·σ_a, b ± 1.96·σ_b.\n",
    "We can also use a **bootstrap** to check robustness."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ci95(mu, sigma):\n",
    "    return (mu - 1.96*sigma, mu + 1.96*sigma)\n",
    "\n",
    "ci_a = ci95(a_fit, a_err)\n",
    "ci_b = ci95(b_fit, b_err)\n",
    "print(f\"95% CI (cov): a in [{ci_a[0]:.4f}, {ci_a[1]:.4f}], b in [{ci_b[0]:.4f}, {ci_b[1]:.4f}]\")\n",
    "\n",
    "# --- Simple residual bootstrap ---\n",
    "B = 500\n",
    "a_boot = np.empty(B)\n",
    "b_boot = np.empty(B)\n",
    "for k in range(B):\n",
    "    resampled = np.random.default_rng().choice(res, size=res.size, replace=True)\n",
    "    y_boot = y_fit + resampled\n",
    "    popt_b, pcov_b = curve_fit(model, x, y_boot, p0=popt, sigma=sigma, absolute_sigma=True)\n",
    "    a_boot[k], b_boot[k] = popt_b\n",
    "\n",
    "a_mu, b_mu = np.mean(a_boot), np.mean(b_boot)\n",
    "a_std, b_std = np.std(a_boot, ddof=1), np.std(b_boot, ddof=1)\n",
    "print(f\"Bootstrap mean±std: a = {a_mu:.4f}±{a_std:.4f}, b = {b_mu:.4f}±{b_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting results\n",
    "- If χ²_ν≈1, your point-wise uncertainties are broadly consistent.\n",
    "- Compare covariance-based CIs with bootstrap spread; big gaps hint at model mismatch or non-Gaussian noise.\n",
    "- **Systematic vs statistical**: we modeled statistical noise only. Systematic effects (e.g., calibration offset) shift results coherently and must be analyzed from experimental context, **not** from deviation to literature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises (short)\n",
    "1. **Weighted vs unweighted**: Repeat the fit with `sigma=None`. Compare parameters, errors, and χ²_ν.\n",
    "2. **Outliers**: Add one outlier (e.g., at the highest x). How do residuals and CIs change?\n",
    "3. **Systematic offset**: Add a constant offset to all y-values. Which parameter(s) change and why? How would you detect this experimentally?\n",
    "4. **Prediction band**: Using the covariance, draw the 95% confidence band of the regression line. What assumptions are implicit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "pygments_lexer": "ipython3" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
