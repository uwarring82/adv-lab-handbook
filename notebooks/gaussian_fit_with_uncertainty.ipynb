{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "deletable": false
   },
   "source": [
    "# Ethical Reminder (from the Lab Alliance Compact)\n",
    "\n",

    "- Data belongs to truth, not expectations; document steps transparently.\n",
    "- Perform **your own analysis**; credit all sources and collaborators properly.\n",
    "- Communicate respectfully; ask for help early; uphold psychological safety.\n",
    "\n",
    "> By proceeding, you acknowledge the Compact and agree to act accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "## Gaussian peak fitting pilot\n",
    "\n",
    "**Learning goals**\n",
    "1. Generate synthetic Gaussian data with known ground truth.\n",
    "2. Perform nonlinear fit using `scipy.optimize.curve_fit`.\n",
    "3. Interpret parameter uncertainties.\n",
    "4. Diagnose fits with residuals.\n",
    "5. Understand systematic vs. statistical uncertainty in peak fitting."

   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "execution_count": null,

   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",

    "\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data\n",
    "\n",
    "We assume the observable is described by a Gaussian with an amplitude, center, width, and constant background.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2024)\n",
    "\n",
    "def gaussian(x, amplitude, mean, sigma, offset):\n",
    "    return amplitude * np.exp(-0.5 * ((x - mean) / sigma) ** 2) + offset\n",
    "\n",
    "x = np.linspace(-5, 5, 120)\n",
    "true_params = {\n",
    "    'amplitude': 3.5,\n",
    "    'mean': 0.6,\n",
    "    'sigma': 0.9,\n",
    "    'offset': 0.25,\n",
    "}\n",
    "sigma_obs = np.full_like(x, 0.15)\n",
    "y_clean = gaussian(x, **true_params)\n",
    "noise = rng.normal(0.0, sigma_obs)\n",
    "y = y_clean + noise\n"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "## Visualize the data\n",
    "\n",
    "Plot the simulated measurements alongside the noise-free model to see the scale of the fluctuations.\n"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.errorbar(x, y, yerr=sigma_obs, fmt='o', markersize=4, capsize=3, label='noisy data')\n",
    "ax.plot(x, y_clean, color='black', lw=2, label='true model')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Signal')\n",
    "ax.set_title('Synthetic Gaussian data with constant background')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Gaussian model\n",
    "\n",
    "`curve_fit` returns both the best-fit parameters and the covariance matrix.\n",
    "Passing `sigma` and `absolute_sigma=True` treats the supplied \u03c3 values as standard deviations of each point.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "p0 = (3.0, 0.0, 1.0, 0.0)  # rough guesses for amplitude, mean, sigma, offset\n",
    "popt, pcov = curve_fit(gaussian, x, y, p0=p0, sigma=sigma_obs, absolute_sigma=True)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "param_names = ('amplitude', 'mean', 'sigma', 'offset')\n",
    "for name, value, err in zip(param_names, popt, perr):\n",
    "    truth = true_params[name]\n",
    "    print(f\"{name:9s} = {value:6.3f} \u00b1 {err:6.3f}  (true: {truth:6.3f})\")\n",
    "\n",
    "residuals = y - gaussian(x, *popt)\n",
    "chi2 = np.sum((residuals / sigma_obs) ** 2)\n",
    "ndof = x.size - len(popt)\n",
    "print(f\"chi^2 = {chi2:.1f}, ndof = {ndof}, chi^2/ndof = {chi2/ndof:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual analysis\n",
    "\n",
    "Residuals help diagnose structure that the model misses. Random scatter about zero suggests an adequate model.\n"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6), sharex=True)\n",
    "model_y = gaussian(x, *popt)\n",
    "ax1.errorbar(x, y, yerr=sigma_obs, fmt='o', markersize=4, capsize=3, label='data')\n",
    "ax1.plot(x, model_y, color='tab:red', label='fit')\n",
    "ax1.set_ylabel('Signal')\n",
    "ax1.set_title('Best-fit Gaussian model')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.axhline(0.0, color='black', lw=1)\n",
    "ax2.errorbar(x, residuals, yerr=sigma_obs, fmt='o', markersize=4, capsize=3)\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residuals with 1\u03c3 error bars')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Explore sensitivity to outliers and systematic offsets\n",
    "    y_outlier = y.copy()\n",
    "    outlier_index = np.argmax(model_y)\n",
    "    y_outlier[outlier_index] += 1.0  # introduce a single large spike\n",
    "\n",
    "    y_offset = y + 0.2  # mimic an uncorrected background shift\n",
    "\n",
    "    popt_outlier, _ = curve_fit(gaussian, x, y_outlier, p0=popt, sigma=sigma_obs, absolute_sigma=True)\n",
    "    popt_offset, _ = curve_fit(gaussian, x, y_offset, p0=popt, sigma=sigma_obs, absolute_sigma=True)\n",
    "\n",
    "    print('Parameter shifts from a single outlier:')\n",
    "    for name, base, pert in zip(param_names, popt, popt_outlier):\n",
    "        print(f\"  {name:9s}: {base:6.3f} \u2192 {pert:6.3f}\")\n",
    "\n",
    "    print('\n",
    "Parameter shifts from a +0.2 systematic offset:')\n",
    "    for name, base, pert in zip(param_names, popt, popt_offset):\n",
    "        print(f\"  {name:9s}: {base:6.3f} \u2192 {pert:6.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting results\n",
    "- \u03c7\u00b2 close to the number of degrees of freedom indicates the point-by-point uncertainties are realistic.\n",
    "- Correlated parameters (e.g., amplitude vs. offset) can inflate uncertainties; inspect `pcov`.\n",
    "- Outliers disproportionately affect the fit: robust estimators or data-quality flags may be necessary.\n",
    "- A global offset shifts the background term without fixing the underlying cause\u2014verify calibrations and subtraction steps.\n"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "## Exercises (short)\n",
    "1. **Noise level**: Change `sigma_obs` and regenerate the data. How do parameter errors scale with noise?\n",
    "2. **Weighted vs unweighted**: Repeat the fit with `sigma=None`. What happens to \u03c7\u00b2 and parameter uncertainties?\n",
    "3. **Outlier handling**: Remove or down-weight the injected outlier in the sensitivity cell. How do the parameters respond?\n",
    "4. **Systematic offset**: Model the +0.2 offset explicitly (e.g., by fitting an additional baseline parameter informed by calibration data). What experimental cross-checks would reveal such a bias?\n"

   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",

   "pygments_lexer": "ipython3"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}