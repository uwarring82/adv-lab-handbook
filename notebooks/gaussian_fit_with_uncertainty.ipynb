{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1006e57",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Ethical Reminder (from the Lab Alliance Compact)\n",
    "\n",
    "- Data belongs to truth, not expectations; document steps transparently.\n",
    "- Perform **your own analysis**; credit all sources and collaborators properly.\n",
    "- Communicate respectfully; ask for help early; uphold psychological safety.\n",
    "\n",
    "> By proceeding, you acknowledge the Compact and agree to act accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bdc71",
   "metadata": {},
   "source": [
    "## Gaussian peak fitting pilot\n",
    "\n",
    "**Learning goals**\n",
    "1. Generate synthetic Gaussian data with known ground truth.\n",
    "2. Perform nonlinear fit using `scipy.optimize.curve_fit`.\n",
    "3. Interpret parameter uncertainties.\n",
    "4. Diagnose fits with residuals.\n",
    "5. Understand systematic vs. statistical uncertainty in peak fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b1340",
   "metadata": {},
   "source": [
    "## Generate synthetic data\n",
    "\n",
    "We assume the observable is described by a Gaussian with an amplitude, center, width, and constant background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2024)\n",
    "\n",
    "def gaussian(x, amplitude, mean, sigma, offset):\n",
    "    return amplitude * np.exp(-0.5 * ((x - mean) / sigma) ** 2) + offset\n",
    "\n",
    "x = np.linspace(-5, 5, 120)\n",
    "true_params = {\n",
    "    'amplitude': 3.5,\n",
    "    'mean': 0.6,\n",
    "    'sigma': 0.9,\n",
    "    'offset': 0.25,\n",
    "}\n",
    "sigma_obs = np.full_like(x, 0.15)\n",
    "y_clean = gaussian(x, **true_params)\n",
    "noise = rng.normal(0.0, sigma_obs)\n",
    "y = y_clean + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98038c0f",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Plot the simulated measurements alongside the noise-free model to see the scale of the fluctuations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.errorbar(x, y, yerr=sigma_obs, fmt='o', markersize=4, capsize=3, label='noisy data')\n",
    "ax.plot(x, y_clean, color='black', lw=2, label='true model')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Signal')\n",
    "ax.set_title('Synthetic Gaussian data with constant background')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7213ba",
   "metadata": {},
   "source": [
    "## Fit the Gaussian model\n",
    "\n",
    "`curve_fit` returns both the best-fit parameters and the covariance matrix.\n",
    "Passing `sigma` and `absolute_sigma=True` treats the supplied σ values as standard deviations of each point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = (3.0, 0.0, 1.0, 0.0)  # rough guesses for amplitude, mean, sigma, offset\n",
    "popt, pcov = curve_fit(gaussian, x, y, p0=p0, sigma=sigma_obs, absolute_sigma=True)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "param_names = ('amplitude', 'mean', 'sigma', 'offset')\n",
    "for name, value, err in zip(param_names, popt, perr):\n",
    "    truth = true_params[name]\n",
    "    print(f\"{name:9s} = {value:6.3f} ± {err:6.3f}  (true: {truth:6.3f})\")\n",
    "\n",
    "residuals = y - gaussian(x, *popt)\n",
    "chi2 = np.sum((residuals / sigma_obs) ** 2)\n",
    "ndof = x.size - len(popt)\n",
    "print(f\"chi^2 = {chi2:.1f}, ndof = {ndof}, chi^2/ndof = {chi2/ndof:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45b671",
   "metadata": {},
   "source": [
    "## Residual analysis\n",
    "\n",
    "Residuals help diagnose structure that the model misses. Random scatter about zero suggests an adequate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73043520",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6), sharex=True)\n",
    "model_y = gaussian(x, *popt)\n",
    "ax1.errorbar(x, y, yerr=sigma_obs, fmt='o', markersize=4, capsize=3, label='data')\n",
    "ax1.plot(x, model_y, color='tab:red', label='fit')\n",
    "ax1.set_ylabel('Signal')\n",
    "ax1.set_title('Best-fit Gaussian model')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.axhline(0.0, color='black', lw=1)\n",
    "ax2.errorbar(x, residuals, yerr=sigma_obs, fmt='o', markersize=4, capsize=3)\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Residuals with 1σ error bars')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Outlier experiment (for exercises)\n",
    "import numpy as np\n",
    "\n",
    "y_outlier = y.copy()\n",
    "# Add a single strong outlier near the maximum x\n",
    "idx = np.argmax(x)\n",
    "y_outlier[idx] += 2.0  # bump up by 2 units\n",
    "\n",
    "# Fit again with outlier\n",
    "popt_o, pcov_o = curve_fit(gauss, x, y_outlier, p0=p0)\n",
    "perr_o = np.sqrt(np.diag(pcov_o))\n",
    "\n",
    "print(\"With outlier:\")\n",
    "for name, val, err in zip(['A','x0','sigma','C'], popt_o, perr_o):\n",
    "    print(f\"{name:5s} = {val:7.3f} ± {err:5.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b7bf0",
   "metadata": {},
   "source": [
    "### Interpreting results\n",
    "- χ² close to the number of degrees of freedom indicates the point-by-point uncertainties are realistic.\n",
    "- Correlated parameters (e.g., amplitude vs. offset) can inflate uncertainties; inspect `pcov`.\n",
    "- Outliers disproportionately affect the fit: robust estimators or data-quality flags may be necessary.\n",
    "- A global offset shifts the background term without fixing the underlying cause—verify calibrations and subtraction steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04be76cf",
   "metadata": {},
   "source": [
    "## Exercises (short)\n",
    "1. **Noise level**: Change `sigma_obs` and regenerate the data. How do parameter errors scale with noise?\n",
    "2. **Weighted vs unweighted**: Repeat the fit with `sigma=None`. What happens to χ² and parameter uncertainties?\n",
    "3. **Outlier handling**: Remove or down-weight the injected outlier in the sensitivity cell. How do the parameters respond?\n",
    "4. **Systematic offset**: Model the +0.2 offset explicitly (e.g., by fitting an additional baseline parameter informed by calibration data). What experimental cross-checks would reveal such a bias?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
