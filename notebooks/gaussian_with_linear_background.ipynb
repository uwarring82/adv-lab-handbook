{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42287b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Ethical Reminder (from the Lab Alliance Compact)\n",
    "\n",
    "- Data belongs to truth, not expectations; document steps transparently.\n",
    "- Perform **your own analysis**; credit all sources and collaborators properly.\n",
    "- Communicate respectfully; ask for help early; uphold psychological safety.\n",
    "\n",
    "> By proceeding, you acknowledge the Compact and agree to act accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438cdd9",
   "metadata": {},
   "source": [
    "# Gaussian peak with linear background\n",
    "\n",
    "**Learning goals**\n",
    "\n",
    "- Demonstrate bias when background is neglected.\n",
    "- Fit wrong model (Gaussian only) vs correct model (Gaussian + linear background).\n",
    "- Compare parameter estimates, residuals, and AIC.\n",
    "- Highlight that this is a systematic modeling issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "def gauss(x, A, x0, sigma, C):\n",
    "    return A*np.exp(-(x-x0)**2/(2*sigma**2)) + C\n",
    "\n",
    "def gauss_linbg(x, A, x0, sigma, m, c):\n",
    "    return A*np.exp(-(x-x0)**2/(2*sigma**2)) + (m*x + c)\n",
    "\n",
    "# Ground truth (with background!)\n",
    "A_true, x0_true, sigma_true = 5.0, 0.5, 0.8\n",
    "m_true, c_true = 0.15, 0.3\n",
    "N = 120\n",
    "x = np.linspace(-3, 4, N)\n",
    "y_true = gauss_linbg(x, A_true, x0_true, sigma_true, m_true, c_true)\n",
    "sigma_y = 0.15  # homoscedastic noise for simplicity\n",
    "y = y_true + rng.normal(0, sigma_y, size=N)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x, y, 'o', ms=3, label='data')\n",
    "plt.plot(x, y_true, '-', label='true (gauss + linear bg)')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.legend(); plt.title('Data with linear background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367267",
   "metadata": {},
   "source": [
    "## Wrong model: Gaussian-only\n",
    "Ignoring the linear background forces the Gaussian parameters to absorb the slope, so we expect biased estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_wrong = [4.0, 0.0, 1.0, 0.0]  # [A, x0, sigma, C]\n",
    "def gauss_only(x, A, x0, sigma, C):\n",
    "    return A*np.exp(-(x-x0)**2/(2*sigma**2)) + C\n",
    "\n",
    "popt_w, pcov_w = curve_fit(gauss_only, x, y, p0=p0_wrong)\n",
    "perr_w = np.sqrt(np.diag(pcov_w))\n",
    "\n",
    "print(\"WRONG model (no linear background):\")\n",
    "for name, val, err in zip(['A','x0','sigma','C'], popt_w, perr_w):\n",
    "    print(f\"{name:6s} = {val:8.3f} ± {err:6.3f}\")\n",
    "\n",
    "y_fit_w = gauss_only(x, *popt_w)\n",
    "res_w = y - y_fit_w\n",
    "\n",
    "import math\n",
    "def aic(y_obs, y_hat, k, sigma):\n",
    "    # Gaussian likelihood with known sigma -> equivalent up to a constant\n",
    "    # Use RSS/sigma^2 proxy; relative comparisons suffice\n",
    "    rss = np.sum((y_obs - y_hat)**2)\n",
    "    n = len(y_obs)\n",
    "    return n*np.log(rss/n) + 2*k\n",
    "\n",
    "AIC_w = aic(y, y_fit_w, k=4, sigma=sigma_y)\n",
    "AIC_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a55491",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(6,6), sharex=True)\n",
    "ax1.plot(x, y, 'o', ms=3, label='data')\n",
    "ax1.plot(x, y_fit_w, '-', label='wrong fit (gauss+const)')\n",
    "ax1.set_ylabel('y'); ax1.legend(); ax1.set_title('Wrong model fit')\n",
    "\n",
    "ax2.axhline(0,color='k',lw=1)\n",
    "ax2.plot(x, res_w, 'o', ms=3)\n",
    "ax2.set_xlabel('x'); ax2.set_ylabel('residuals'); ax2.set_title('Residuals (systematic trend?)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511571f",
   "metadata": {},
   "source": [
    "## Correct model: Gaussian + linear background\n",
    "Including the background should reduce residual structure and recover unbiased parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_right = [4.0, 0.0, 1.0, 0.1, 0.0]  # [A, x0, sigma, m, c]\n",
    "popt_r, pcov_r = curve_fit(gauss_linbg, x, y, p0=p0_right)\n",
    "perr_r = np.sqrt(np.diag(pcov_r))\n",
    "\n",
    "print(\"RIGHT model (gauss + linear background):\")\n",
    "for name, val, err in zip(['A','x0','sigma','m','c'], popt_r, perr_r):\n",
    "    print(f\"{name:6s} = {val:8.3f} ± {err:6.3f}\")\n",
    "\n",
    "y_fit_r = gauss_linbg(x, *popt_r)\n",
    "res_r = y - y_fit_r\n",
    "AIC_r = aic(y, y_fit_r, k=5, sigma=sigma_y)\n",
    "print(f\"AIC wrong: {AIC_w:.2f}   AIC right: {AIC_r:.2f}   (lower is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04255346",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(10,7), sharex='col')\n",
    "axs[0,0].plot(x,y,'o',ms=3); axs[0,0].plot(x,y_fit_w,'-',label='wrong'); axs[0,0].set_title('Wrong fit')\n",
    "axs[0,1].plot(x,y,'o',ms=3); axs[0,1].plot(x,y_fit_r,'-',label='right'); axs[0,1].set_title('Right fit')\n",
    "\n",
    "axs[1,0].axhline(0,color='k',lw=1); axs[1,0].plot(x,res_w,'o',ms=3); axs[1,0].set_title('Residuals (wrong)')\n",
    "axs[1,1].axhline(0,color='k',lw=1); axs[1,1].plot(x,res_r,'o',ms=3); axs[1,1].set_title('Residuals (right)')\n",
    "\n",
    "for ax in axs[1,:]:\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('residuals')\n",
    "for ax in axs[0,:]:\n",
    "    ax.set_ylabel('y')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b396b7c",
   "metadata": {},
   "source": [
    "### Interpretation & Takeaways\n",
    "\n",
    "- **Bias from model misspecification**: Ignoring a linear background forces the Gaussian parameters to absorb the slope → biased A, x0, σ estimates.\n",
    "- **Residual trends**: The wrong model leaves systematic trends in residuals; the right model residuals are closer to structureless noise.\n",
    "- **Model selection**: Compare fits with AIC (or BIC). Lower AIC indicates better trade-off between fit quality and complexity.\n",
    "- **Systematic vs. statistical**: This is a **systematic** modeling problem. More data won’t remove bias if the model is wrong.\n",
    "- **Experiment design**: Use off-peak regions to estimate background; include background terms in the model when justified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563fa32e",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Increase the true background slope (m_true) to 0.3; refit both models. How do parameter biases change?\n",
    "2. Make noise heteroscedastic (σ increasing with x). Does that alter residual patterns or parameter uncertainties?\n",
    "3. Add a quadratic background term; test if the linear model remains adequate (compare AIC).\n",
    "4. Try a residual bootstrap for the **correct** model and compare the CI widths to the covariance-based errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
